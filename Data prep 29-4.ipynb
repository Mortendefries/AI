{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_df = pd.read_csv('cab_rides.csv')\n",
    "weather_df = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the two csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the timestamp data into real date format\n",
    "rides_df['date_time'] = pd.to_datetime(rides_df['time_stamp']/1000, unit='s')\n",
    "weather_df['date_time'] = pd.to_datetime(weather_df['time_stamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets to reflect the same time for a location, date and hour\n",
    "rides_df['merged_date'] = rides_df.source.astype(str) +\" - \"+ rides_df.date_time.dt.date.astype(\"str\") + \" - \"+ rides_df.date_time.dt.hour.astype(\"str\")\n",
    "weather_df['merged_date'] = weather_df.location.astype(str) +\" - \"+ weather_df.date_time.dt.date.astype(\"str\") + \" - \"+ weather_df.date_time.dt.hour.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(rides_df, weather_df, on=['merged_date'])\n",
    "\n",
    "# Merge from Kaggle, but i used the one above becuase it seems more intuitive \n",
    "#merged_df = UberLyft_df.join(Weather_df, on = ['merged_date'], rsuffix ='_w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1265675 entries, 0 to 1265674\n",
      "Data columns (total 21 columns):\n",
      "distance            1265675 non-null float64\n",
      "cab_type            1265675 non-null object\n",
      "time_stamp_x        1265675 non-null int64\n",
      "destination         1265675 non-null object\n",
      "source              1265675 non-null object\n",
      "price               1164996 non-null float64\n",
      "surge_multiplier    1265675 non-null float64\n",
      "id                  1265675 non-null object\n",
      "product_id          1265675 non-null object\n",
      "name                1265675 non-null object\n",
      "date_time_x         1265675 non-null datetime64[ns]\n",
      "merged_date         1265675 non-null object\n",
      "temp                1265675 non-null float64\n",
      "location            1265675 non-null object\n",
      "clouds              1265675 non-null float64\n",
      "pressure            1265675 non-null float64\n",
      "rain                206947 non-null float64\n",
      "time_stamp_y        1265675 non-null int64\n",
      "humidity            1265675 non-null float64\n",
      "wind                1265675 non-null float64\n",
      "date_time_y         1265675 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(9), int64(2), object(8)\n",
      "memory usage: 212.4+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the merged dataframe consists of 1.265.675 entries while the original dataset had 693.071 entries this is because the weather data has been recorded more than one time for the same hour, and since we merge by hour (since the rides and weather do not have the exact same timestamp), then we end up with rides having different weather attributes adn therefore more the one row of ride than one. This can be seen in the following since each id can occur multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing an fixing the merge issue explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1b446c5a-efd1-4004-9275-13bb456af595    15\n",
       "5f66a01e-d637-4c8a-9136-5c2fee0c1992    15\n",
       "d035a22f-c58d-4469-9504-382ae1d2f7c6    15\n",
       "f34605f4-e1cc-4217-88a0-44c37afc36c2    15\n",
       "72db179b-ef0b-44e6-8d26-6ea60e5f6bfa    15\n",
       "                                        ..\n",
       "07ea06ca-8a1d-42f8-94df-d1e79a4815de     1\n",
       "f859c81b-618e-4563-bbbc-2fe3e3bbe2eb     1\n",
       "bbb7589e-98b3-49ff-ab3f-debd1aa955b3     1\n",
       "e0c2b7cb-4874-4b50-b6a5-72d099434649     1\n",
       "e84c3b4a-5293-449a-aa26-5f6a83266cff     1\n",
       "Name: id, Length: 690107, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of how many instances there is of each trip\n",
    "merged_df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time_x</th>\n",
       "      <th>merged_date</th>\n",
       "      <th>temp</th>\n",
       "      <th>location</th>\n",
       "      <th>clouds</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rain</th>\n",
       "      <th>time_stamp_y</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>date_time_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>900564</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.54</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212884</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2018-11-26 06:14:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900565</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.55</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213005</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2018-11-26 06:16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900566</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.61</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213443</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2018-11-26 06:24:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900567</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.53</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212732</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2018-11-26 06:12:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900568</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.55</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212945</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2018-11-26 06:15:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900569</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.55</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212914</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2018-11-26 06:15:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900570</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.53</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212708</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2018-11-26 06:11:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900571</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>41.16</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1014.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543215030</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2018-11-26 06:50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900572</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.64</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213742</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2018-11-26 06:29:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900573</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.54</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212855</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2018-11-26 06:14:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900574</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>41.16</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1014.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543214943</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2018-11-26 06:49:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900575</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.58</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213144</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2018-11-26 06:19:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900576</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>41.16</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1014.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543214984</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2018-11-26 06:49:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900577</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.57</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212974</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2018-11-26 06:16:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900578</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.83</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1014.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543214430</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2018-11-26 06:40:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date_time_x                 merged_date   temp  \\\n",
       "900564 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.54   \n",
       "900565 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.55   \n",
       "900566 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.61   \n",
       "900567 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.53   \n",
       "900568 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.55   \n",
       "900569 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.55   \n",
       "900570 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.53   \n",
       "900571 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  41.16   \n",
       "900572 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.64   \n",
       "900573 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.54   \n",
       "900574 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  41.16   \n",
       "900575 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.58   \n",
       "900576 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  41.16   \n",
       "900577 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.57   \n",
       "900578 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.83   \n",
       "\n",
       "         location  clouds  pressure  rain  time_stamp_y  humidity  wind  \\\n",
       "900564  North End    1.00   1014.19   NaN    1543212884      0.91  1.25   \n",
       "900565  North End    1.00   1014.19   NaN    1543213005      0.91  1.28   \n",
       "900566  North End    1.00   1014.18   NaN    1543213443      0.91  1.38   \n",
       "900567  North End    1.00   1014.19   NaN    1543212732      0.91  1.22   \n",
       "900568  North End    1.00   1014.19   NaN    1543212945      0.91  1.27   \n",
       "900569  North End    1.00   1014.19   NaN    1543212914      0.91  1.26   \n",
       "900570  North End    1.00   1014.19   NaN    1543212708      0.91  1.21   \n",
       "900571  North End    0.98   1014.35   NaN    1543215030      0.92  1.83   \n",
       "900572  North End    1.00   1014.18   NaN    1543213742      0.92  1.45   \n",
       "900573  North End    1.00   1014.19   NaN    1543212855      0.91  1.25   \n",
       "900574  North End    0.98   1014.35   NaN    1543214943      0.92  1.82   \n",
       "900575  North End    1.00   1014.19   NaN    1543213144      0.91  1.31   \n",
       "900576  North End    0.98   1014.35   NaN    1543214984      0.92  1.82   \n",
       "900577  North End    1.00   1014.19   NaN    1543212974      0.91  1.27   \n",
       "900578  North End    0.92   1014.00   NaN    1543214430      0.92  1.71   \n",
       "\n",
       "               date_time_y  \n",
       "900564 2018-11-26 06:14:44  \n",
       "900565 2018-11-26 06:16:45  \n",
       "900566 2018-11-26 06:24:03  \n",
       "900567 2018-11-26 06:12:12  \n",
       "900568 2018-11-26 06:15:45  \n",
       "900569 2018-11-26 06:15:14  \n",
       "900570 2018-11-26 06:11:48  \n",
       "900571 2018-11-26 06:50:30  \n",
       "900572 2018-11-26 06:29:02  \n",
       "900573 2018-11-26 06:14:15  \n",
       "900574 2018-11-26 06:49:03  \n",
       "900575 2018-11-26 06:19:04  \n",
       "900576 2018-11-26 06:49:44  \n",
       "900577 2018-11-26 06:16:14  \n",
       "900578 2018-11-26 06:40:30  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of a specific id that occurs multiple times\n",
    "merged_df[merged_df['id'] == '29ce4d5f-07f9-4ce5-ada4-ae9ea49e92a6'].iloc[:,10:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the weather data for each id is very similar, we choose to make a mean of all the instances by id\n",
    "id_group = pd.DataFrame(merged_df.groupby('id')['temp','clouds', 'pressure', 'rain', 'humidity', 'wind'].mean())\n",
    "merged_uniqueid_df = rides_df.join(id_group, on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 693071 entries, 0 to 693070\n",
      "Data columns (total 18 columns):\n",
      "distance            693071 non-null float64\n",
      "cab_type            693071 non-null object\n",
      "time_stamp          693071 non-null int64\n",
      "destination         693071 non-null object\n",
      "source              693071 non-null object\n",
      "price               637976 non-null float64\n",
      "surge_multiplier    693071 non-null float64\n",
      "id                  693071 non-null object\n",
      "product_id          693071 non-null object\n",
      "name                693071 non-null object\n",
      "date_time           693071 non-null datetime64[ns]\n",
      "merged_date         693071 non-null object\n",
      "temp                690107 non-null float64\n",
      "clouds              690107 non-null float64\n",
      "pressure            690107 non-null float64\n",
      "rain                118677 non-null float64\n",
      "humidity            690107 non-null float64\n",
      "wind                690107 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(9), int64(1), object(7)\n",
      "memory usage: 95.2+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_uniqueid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d0048593-9b86-4c58-bfa6-0dac473846ba    1\n",
       "3c71fad4-08c5-451d-816a-7336a07f33b3    1\n",
       "b6dea706-1d2d-48f9-ae4d-8615ecd385f3    1\n",
       "0f49c48a-b83c-4bd9-99a5-60338118b8fb    1\n",
       "8cad2d6d-e04c-49b7-8d57-97536bded006    1\n",
       "                                       ..\n",
       "c113c9df-3420-4d2f-89d2-48d0d3938ec4    1\n",
       "248172c1-a34b-4a44-ace8-1029919d7b69    1\n",
       "8f9d2f94-f066-42f2-9f4e-0b4c98c483c9    1\n",
       "f38fa6b2-f45d-4860-a1af-f945564e8e51    1\n",
       "2ba70250-367f-4d0b-a1c1-de022185f165    1\n",
       "Name: id, Length: 693071, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_uniqueid_df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the df to just \"df\" since it is our final merged df\n",
    "df = merged_uniqueid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance                 0\n",
       "cab_type                 0\n",
       "time_stamp               0\n",
       "destination              0\n",
       "source                   0\n",
       "price                55095\n",
       "surge_multiplier         0\n",
       "id                       0\n",
       "product_id               0\n",
       "name                     0\n",
       "date_time                0\n",
       "merged_date              0\n",
       "temp                  2964\n",
       "clouds                2964\n",
       "pressure              2964\n",
       "rain                574394\n",
       "humidity              2964\n",
       "wind                  2964\n",
       "dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume the null values for 'rain' mean that it did not rain, therefore we change these values to '0'\n",
    "df['rain'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all instances where the price and some wheather conditions is null, assuming this is a mistake\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removing attributes we do not need. This includes date_time since it is incorrect, but we will create a new\n",
    "attribute of this later based on 'time_stamp'. It also involves 'id' since we can just use the index.\n",
    "Also rearraging the attributes in an order that makes more sense.\n",
    "\"\"\"\n",
    "df = df[['cab_type', 'distance', 'time_stamp', 'source', 'destination', 'price', 'surge_multiplier',\n",
    "         'name', 'temp', 'clouds', 'pressure', 'rain', 'humidity', 'wind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index since we have removed several rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding a correct 'date' and 'time' based on 'time_stamp'\n",
    "df[\"rounded_timestamp\"] = df[\"time_stamp\"] / 1000\n",
    "df[\"rounded_timestamp\"] = df[\"rounded_timestamp\"].apply(np.floor)\n",
    "\n",
    "df[\"date\"] = df[\"rounded_timestamp\"].apply(lambda x : datetime.fromtimestamp(x).date())\n",
    "df[\"time\"] = df[\"rounded_timestamp\"].apply(lambda x: datetime.fromtimestamp(x).time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new attributes for weekday, hour of the day and time of the day (if it is morning, afternoon, evening or night)\n",
    "df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "df[\"weekday\"] = df[\"weekday\"].map({0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'})\n",
    "df['hour'] = df['time'].apply(lambda time: time.hour)\n",
    "\n",
    "df.loc[(df.hour >= 6) & (df.hour < 12) , 'time_of_day'] = 'Morning'\n",
    "df.loc[(df.hour >= 12) & (df.hour < 15) , 'time_of_day'] = 'Afternoon'\n",
    "df.loc[(df.hour >= 15) & (df.hour < 18) , 'time_of_day'] = 'Evening'\n",
    "df.loc[(df.hour >= 18) | (df.hour < 6) , 'time_of_day'] = 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCan also be changed to a simple Integer if needed\\ndf[\"date\"] = pd.to_datetime(df[\"date\"]).dt.strftime(\"%Y%m%d\")\\ndf[\\'date\\'].astype(int)\\n'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the date to a datetime datetype instead of object\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "\"\"\"\n",
    "Can also be changed to a simple Integer if needed\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.strftime(\"%Y%m%d\")\n",
    "df['date'].astype(int)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the new attributes and removing 'time_stamp' and 'time' since we do not need it anymore\n",
    "df = df[['cab_type', 'distance', 'source', 'destination', 'price', 'surge_multiplier', 'name',\n",
    "         'date', 'weekday', 'hour', 'time_of_day',\n",
    "         'temp', 'clouds', 'pressure', 'rain', 'humidity', 'wind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp</th>\n",
       "      <th>clouds</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rain</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-16</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10</td>\n",
       "      <td>Morning</td>\n",
       "      <td>38.460</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>1022.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lux</td>\n",
       "      <td>2018-11-27</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>44.065</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>1002.88</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>12.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>Night</td>\n",
       "      <td>35.080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1013.71</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>Night</td>\n",
       "      <td>37.680</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>998.42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lux Black</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>19</td>\n",
       "      <td>Night</td>\n",
       "      <td>40.780</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1000.15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cab_type  distance            source    destination  price  \\\n",
       "0     Lyft      0.44  Haymarket Square  North Station    5.0   \n",
       "1     Lyft      0.44  Haymarket Square  North Station   11.0   \n",
       "2     Lyft      0.44  Haymarket Square  North Station   26.0   \n",
       "3     Lyft      0.44  Haymarket Square  North Station    9.0   \n",
       "4     Lyft      0.44  Haymarket Square  North Station   16.5   \n",
       "\n",
       "   surge_multiplier          name       date   weekday  hour time_of_day  \\\n",
       "0               1.0        Shared 2018-12-16    Sunday    10     Morning   \n",
       "1               1.0           Lux 2018-11-27   Tuesday     3       Night   \n",
       "2               1.0  Lux Black XL 2018-11-30    Friday     5       Night   \n",
       "3               1.0       Lyft XL 2018-11-29  Thursday     4       Night   \n",
       "4               1.0     Lux Black 2018-12-17    Monday    19       Night   \n",
       "\n",
       "     temp    clouds  pressure   rain  humidity   wind  \n",
       "0  38.460  0.290000   1022.25  0.000  0.760000   7.68  \n",
       "1  44.065  0.995000   1002.88  0.106  0.895000  12.63  \n",
       "2  35.080  0.000000   1013.71  0.000  0.700000   5.25  \n",
       "3  37.680  0.433333    998.42  0.000  0.706667  11.16  \n",
       "4  40.780  0.930000   1000.15  0.000  0.790000   7.55  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making two dataframes based on 'cab_type'. By this creating one for Uber and one for\n",
    "Lyft in order to analyze them seperately and compare them.\n",
    "\"\"\"\n",
    "uber_df = df[df['cab_type'] ==\"Uber\"]\n",
    "lyft_df = df[df['cab_type'] ==\"Lyft\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Status:\n",
    "We now have 3 dataframes: 'df', 'uber_df', 'lyft_df'. These are merged with the weather based\n",
    "on the source location, the date and the hour of the date.\n",
    "\n",
    "To do in date prep:\n",
    "- Fix headlines -> Morten\n",
    "- Fix headlines -> Morten\n",
    "- Make baseline and importances -> Morten\n",
    "- Make visualization -> see Data prep_cab or https://www.kaggle.com/cempek/uber-vs-lyft-visualizations from step 11\n",
    "\n",
    "- Remove 'hour' attribute if we do not use it\n",
    "- Change datetypes if we can't use them ('datetime' and object datetypes e.g., 'cab_type' and 'source'\n",
    "    - Syntax for object to int for binary values -> df['cab_type'] = pd.get_dummies(df['cab_type'])\n",
    "\n",
    "To do under modelling:\n",
    "- Clean 'surge_multiplier' if needed in the model\n",
    "- Normalize attributes to make them more hetereogenous if needed in the model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'PreppedDataSet.csv', index=False)\n",
    "uber_df.to_csv(r'UberDataSet.csv', index=False)\n",
    "lyft_df.to_csv(r'LyftDataSet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
