{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_df = pd.read_csv('cab_rides.csv')\n",
    "weather_df = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the two csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the timestamp data into real date format\n",
    "rides_df['date_time'] = pd.to_datetime(rides_df['time_stamp']/1000, unit='s')\n",
    "weather_df['date_time'] = pd.to_datetime(weather_df['time_stamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets to reflect the same time for a location, date and hour\n",
    "rides_df['merged_date'] = rides_df.source.astype(str) +\" - \"+ rides_df.date_time.dt.date.astype(\"str\") + \" - \"+ rides_df.date_time.dt.hour.astype(\"str\")\n",
    "weather_df['merged_date'] = weather_df.location.astype(str) +\" - \"+ weather_df.date_time.dt.date.astype(\"str\") + \" - \"+ weather_df.date_time.dt.hour.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rides['date'].dt.strftime('%m').head() <-- Really don't know what this done or why it is necessary\n",
    "# that is why it is commented. Maybe figure it out?\n",
    "# Weather_df.index = Weather_df['merged_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(rides_df, weather_df, on=['merged_date'])\n",
    "\n",
    "# Merge from Kaggle, but i used the one above becuase it seems more intuitive \n",
    "#merged_df = UberLyft_df.join(Weather_df, on = ['merged_date'], rsuffix ='_w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1265675 entries, 0 to 1265674\n",
      "Data columns (total 21 columns):\n",
      "distance            1265675 non-null float64\n",
      "cab_type            1265675 non-null object\n",
      "time_stamp_x        1265675 non-null int64\n",
      "destination         1265675 non-null object\n",
      "source              1265675 non-null object\n",
      "price               1164996 non-null float64\n",
      "surge_multiplier    1265675 non-null float64\n",
      "id                  1265675 non-null object\n",
      "product_id          1265675 non-null object\n",
      "name                1265675 non-null object\n",
      "date_time_x         1265675 non-null datetime64[ns]\n",
      "merged_date         1265675 non-null object\n",
      "temp                1265675 non-null float64\n",
      "location            1265675 non-null object\n",
      "clouds              1265675 non-null float64\n",
      "pressure            1265675 non-null float64\n",
      "rain                206947 non-null float64\n",
      "time_stamp_y        1265675 non-null int64\n",
      "humidity            1265675 non-null float64\n",
      "wind                1265675 non-null float64\n",
      "date_time_y         1265675 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(9), int64(2), object(8)\n",
      "memory usage: 212.4+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the merged dataframe consists of 1.265.675 entries while the original dataset had 693.071 entries this is because the weather data has been recorded more than one time for the same hour, and since we merge by hour (since the rides and weather do not have the exact same timestamp), then we end up with rides having different weather attributes adn therefore more the one row of ride than one. This can be seen in the following since each id can occur multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing an fixing the merge issue explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "beb3a733-1c3a-4ffb-bef1-d958d369b6e6    15\n",
       "d322a910-138e-45d9-8c11-d5e23667d124    15\n",
       "da6ce913-13ac-48db-aff6-9699bd7173ed    15\n",
       "098db1b0-446a-4377-ab17-bfffc6d78936    15\n",
       "49e16960-e54c-43fd-973a-b6f82ce9c7f0    15\n",
       "                                        ..\n",
       "7040cf4d-2c8a-4866-b04f-89fa52e269b5     1\n",
       "627b85c7-0acc-4f1d-b0c6-835a56be0fb3     1\n",
       "0f174034-7bea-4440-bf33-d3d441fbf03e     1\n",
       "7754a1dd-7b99-4591-babc-a61bf8aa9d18     1\n",
       "6b9d726b-d257-4e36-b61e-012045671e18     1\n",
       "Name: id, Length: 690107, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of how many instances there is of each trip\n",
    "merged_df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time_x</th>\n",
       "      <th>merged_date</th>\n",
       "      <th>temp</th>\n",
       "      <th>location</th>\n",
       "      <th>clouds</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rain</th>\n",
       "      <th>time_stamp_y</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>date_time_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>900564</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.54</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212884</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2018-11-26 06:14:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900565</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.55</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213005</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2018-11-26 06:16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900566</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.61</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213443</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2018-11-26 06:24:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900567</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.53</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212732</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2018-11-26 06:12:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900568</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.55</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212945</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2018-11-26 06:15:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900569</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.55</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212914</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2018-11-26 06:15:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900570</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.53</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212708</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2018-11-26 06:11:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900571</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>41.16</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1014.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543215030</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2018-11-26 06:50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900572</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.64</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213742</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2018-11-26 06:29:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900573</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.54</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212855</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2018-11-26 06:14:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900574</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>41.16</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1014.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543214943</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2018-11-26 06:49:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900575</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.58</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543213144</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2018-11-26 06:19:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900576</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>41.16</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1014.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543214984</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2018-11-26 06:49:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900577</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.57</td>\n",
       "      <td>North End</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543212974</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2018-11-26 06:16:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900578</td>\n",
       "      <td>2018-11-26 06:14:16.085999966</td>\n",
       "      <td>North End - 2018-11-26 - 6</td>\n",
       "      <td>40.83</td>\n",
       "      <td>North End</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1014.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543214430</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2018-11-26 06:40:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date_time_x                 merged_date   temp  \\\n",
       "900564 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.54   \n",
       "900565 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.55   \n",
       "900566 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.61   \n",
       "900567 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.53   \n",
       "900568 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.55   \n",
       "900569 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.55   \n",
       "900570 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.53   \n",
       "900571 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  41.16   \n",
       "900572 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.64   \n",
       "900573 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.54   \n",
       "900574 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  41.16   \n",
       "900575 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.58   \n",
       "900576 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  41.16   \n",
       "900577 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.57   \n",
       "900578 2018-11-26 06:14:16.085999966  North End - 2018-11-26 - 6  40.83   \n",
       "\n",
       "         location  clouds  pressure  rain  time_stamp_y  humidity  wind  \\\n",
       "900564  North End    1.00   1014.19   NaN    1543212884      0.91  1.25   \n",
       "900565  North End    1.00   1014.19   NaN    1543213005      0.91  1.28   \n",
       "900566  North End    1.00   1014.18   NaN    1543213443      0.91  1.38   \n",
       "900567  North End    1.00   1014.19   NaN    1543212732      0.91  1.22   \n",
       "900568  North End    1.00   1014.19   NaN    1543212945      0.91  1.27   \n",
       "900569  North End    1.00   1014.19   NaN    1543212914      0.91  1.26   \n",
       "900570  North End    1.00   1014.19   NaN    1543212708      0.91  1.21   \n",
       "900571  North End    0.98   1014.35   NaN    1543215030      0.92  1.83   \n",
       "900572  North End    1.00   1014.18   NaN    1543213742      0.92  1.45   \n",
       "900573  North End    1.00   1014.19   NaN    1543212855      0.91  1.25   \n",
       "900574  North End    0.98   1014.35   NaN    1543214943      0.92  1.82   \n",
       "900575  North End    1.00   1014.19   NaN    1543213144      0.91  1.31   \n",
       "900576  North End    0.98   1014.35   NaN    1543214984      0.92  1.82   \n",
       "900577  North End    1.00   1014.19   NaN    1543212974      0.91  1.27   \n",
       "900578  North End    0.92   1014.00   NaN    1543214430      0.92  1.71   \n",
       "\n",
       "               date_time_y  \n",
       "900564 2018-11-26 06:14:44  \n",
       "900565 2018-11-26 06:16:45  \n",
       "900566 2018-11-26 06:24:03  \n",
       "900567 2018-11-26 06:12:12  \n",
       "900568 2018-11-26 06:15:45  \n",
       "900569 2018-11-26 06:15:14  \n",
       "900570 2018-11-26 06:11:48  \n",
       "900571 2018-11-26 06:50:30  \n",
       "900572 2018-11-26 06:29:02  \n",
       "900573 2018-11-26 06:14:15  \n",
       "900574 2018-11-26 06:49:03  \n",
       "900575 2018-11-26 06:19:04  \n",
       "900576 2018-11-26 06:49:44  \n",
       "900577 2018-11-26 06:16:14  \n",
       "900578 2018-11-26 06:40:30  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of a specific id that occurs multiple times\n",
    "merged_df[merged_df['id'] == '29ce4d5f-07f9-4ce5-ada4-ae9ea49e92a6'].iloc[:,10:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the weather data for each id is very similar, we choose to make a mean of all the instances by id\n",
    "id_group = pd.DataFrame(merged_df.groupby('id')['temp','clouds', 'pressure', 'rain', 'humidity', 'wind'].mean())\n",
    "merged_uniqueid_df = rides_df.join(id_group, on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 693071 entries, 0 to 693070\n",
      "Data columns (total 18 columns):\n",
      "distance            693071 non-null float64\n",
      "cab_type            693071 non-null object\n",
      "time_stamp          693071 non-null int64\n",
      "destination         693071 non-null object\n",
      "source              693071 non-null object\n",
      "price               637976 non-null float64\n",
      "surge_multiplier    693071 non-null float64\n",
      "id                  693071 non-null object\n",
      "product_id          693071 non-null object\n",
      "name                693071 non-null object\n",
      "date_time           693071 non-null datetime64[ns]\n",
      "merged_date         693071 non-null object\n",
      "temp                690107 non-null float64\n",
      "clouds              690107 non-null float64\n",
      "pressure            690107 non-null float64\n",
      "rain                118677 non-null float64\n",
      "humidity            690107 non-null float64\n",
      "wind                690107 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(9), int64(1), object(7)\n",
      "memory usage: 95.2+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_uniqueid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55618c50-cc80-4d19-b9e9-e539b0487e1d    1\n",
       "6d6197bd-3724-455c-86af-296a9962c670    1\n",
       "d1f2108f-338b-4f6d-9216-1034ef5bd189    1\n",
       "fd615731-0393-4d61-9a64-e15ba530e9cd    1\n",
       "7f71d694-b1da-41d5-a0e7-a8f122205c66    1\n",
       "                                       ..\n",
       "a900e581-271b-4bc0-bcfc-4d16ea41c9c3    1\n",
       "757dc217-a3db-46ae-aa4f-39f83fc3bcc7    1\n",
       "f45c3e39-ea54-4dcd-af96-c8bc8abd1eb9    1\n",
       "4c63eb11-e536-4198-a834-f0837bb607b6    1\n",
       "6b9d726b-d257-4e36-b61e-012045671e18    1\n",
       "Name: id, Length: 693071, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_uniqueid_df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to continue see https://www.kaggle.com/cempek/uber-vs-lyft-visualizations from step 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the df to just \"df\" since it is our final merged df\n",
    "df = merged_uniqueid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance                 0\n",
       "cab_type                 0\n",
       "time_stamp               0\n",
       "destination              0\n",
       "source                   0\n",
       "price                55095\n",
       "surge_multiplier         0\n",
       "id                       0\n",
       "product_id               0\n",
       "name                     0\n",
       "date_time                0\n",
       "merged_date              0\n",
       "temp                  2964\n",
       "clouds                2964\n",
       "pressure              2964\n",
       "rain                574394\n",
       "humidity              2964\n",
       "wind                  2964\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume the null values for 'rain' mean that it did not rain, therefore we change these values to '0'\n",
    "df['rain'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all instances where the price and some wheather conditions is null, assuming this is a mistake\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removing attributes we do not need. This includes date_time since it is incorrect, but we will create a new\n",
    "attribute of this later based on 'time_stamp'. It also involves 'id' since we can just use the index.\n",
    "Also rearraging the attributes in an order that makes more sense.\n",
    "\"\"\"\n",
    "df = df[['cab_type', 'distance', 'time_stamp', 'source', 'destination', 'price', 'surge_multiplier',\n",
    "         'name', 'temp', 'clouds', 'pressure', 'rain', 'humidity', 'wind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index since we have removed several rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding a correct 'date' and 'time' based on 'time_stamp'\n",
    "df[\"rounded_timestamp\"] = df[\"time_stamp\"] / 1000\n",
    "df[\"rounded_timestamp\"] = df[\"rounded_timestamp\"].apply(np.floor)\n",
    "\n",
    "df[\"date\"] = df[\"rounded_timestamp\"].apply(lambda x : datetime.fromtimestamp(x).date())\n",
    "df[\"time\"] = df[\"rounded_timestamp\"].apply(lambda x: datetime.fromtimestamp(x).time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new attributes for weekday, hour of the day and time of the day (if it is morning, afternoon, evening or night)\n",
    "df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "df[\"weekday\"] = df[\"weekday\"].map({0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'})\n",
    "df['hour'] = df['time'].apply(lambda time: time.hour)\n",
    "\n",
    "df.loc[(df.hour >= 6) & (df.hour < 12) , 'time_of_day'] = 'Morning'\n",
    "df.loc[(df.hour >= 12) & (df.hour < 15) , 'time_of_day'] = 'Afternoon'\n",
    "df.loc[(df.hour >= 15) & (df.hour < 18) , 'time_of_day'] = 'Evening'\n",
    "df.loc[(df.hour >= 18) | (df.hour < 6) , 'time_of_day'] = 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the new attributes and removing 'time_stamp' since we do not need it anymore\n",
    "df = df[['cab_type', 'distance', 'source', 'destination', 'price', 'surge_multiplier', 'name',\n",
    "         'date', 'time', 'weekday', 'hour', 'time_of_day',\n",
    "         'temp', 'clouds', 'pressure', 'rain', 'humidity', 'wind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>temp</th>\n",
       "      <th>clouds</th>\n",
       "      <th>pressure</th>\n",
       "      <th>rain</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-16</td>\n",
       "      <td>10:30:07</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10</td>\n",
       "      <td>Morning</td>\n",
       "      <td>38.460</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>1022.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lux</td>\n",
       "      <td>2018-11-27</td>\n",
       "      <td>03:00:23</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>3</td>\n",
       "      <td>Night</td>\n",
       "      <td>44.065</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>1002.88</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>12.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>05:53:02</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>Night</td>\n",
       "      <td>35.080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1013.71</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>04:49:20</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>Night</td>\n",
       "      <td>37.680</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>998.42</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>North Station</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lux Black</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>19:25:12</td>\n",
       "      <td>Monday</td>\n",
       "      <td>19</td>\n",
       "      <td>Night</td>\n",
       "      <td>40.780</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1000.15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cab_type  distance            source    destination  price  \\\n",
       "0     Lyft      0.44  Haymarket Square  North Station    5.0   \n",
       "1     Lyft      0.44  Haymarket Square  North Station   11.0   \n",
       "2     Lyft      0.44  Haymarket Square  North Station   26.0   \n",
       "3     Lyft      0.44  Haymarket Square  North Station    9.0   \n",
       "4     Lyft      0.44  Haymarket Square  North Station   16.5   \n",
       "\n",
       "   surge_multiplier          name        date      time   weekday  hour  \\\n",
       "0               1.0        Shared  2018-12-16  10:30:07    Sunday    10   \n",
       "1               1.0           Lux  2018-11-27  03:00:23   Tuesday     3   \n",
       "2               1.0  Lux Black XL  2018-11-30  05:53:02    Friday     5   \n",
       "3               1.0       Lyft XL  2018-11-29  04:49:20  Thursday     4   \n",
       "4               1.0     Lux Black  2018-12-17  19:25:12    Monday    19   \n",
       "\n",
       "  time_of_day    temp    clouds  pressure   rain  humidity   wind  \n",
       "0     Morning  38.460  0.290000   1022.25  0.000  0.760000   7.68  \n",
       "1       Night  44.065  0.995000   1002.88  0.106  0.895000  12.63  \n",
       "2       Night  35.080  0.000000   1013.71  0.000  0.700000   5.25  \n",
       "3       Night  37.680  0.433333    998.42  0.000  0.706667  11.16  \n",
       "4       Night  40.780  0.930000   1000.15  0.000  0.790000   7.55  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making two dataframes based on 'cab_type'. By this creating one for Uber and one for\n",
    "Lyft in order to analyze them seperately and compare them.\n",
    "\"\"\"\n",
    "uber_df = df[df['cab_type'] ==\"Uber\"]\n",
    "lyft_df = df[df['cab_type'] ==\"Lyft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lyft    306102\n",
       "Name: cab_type, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Status:\n",
    "We now have 3 dataframes: 'df', 'uber_df', 'lyft_df'. These are merged with the weather based\n",
    "on the source location, the date and the hour of the date.\n",
    "\n",
    "What to do or not to do:\n",
    "Make visualization -> see Data prep_cab.\n",
    "Clean 'surge_multiplier', i didn't do it since i was in doubt of why we removed it.\n",
    "Maybe fix the headlines of the dataset.\n",
    "Reconsider if we need the 'hour' attribute.\n",
    "Consider if we can work with the datatypes or we should change these so they are workable (e.g. date and time).\n",
    "Consider to normalize our attributes in order to make it more heterogenous.\n",
    "Consider if we should use the code in the 6th field.\n",
    "Make baseline, importances and start on the models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'PreppedDataSet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
